{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with Optimus\n",
    "\n",
    "Machine Learning is one of the last steps, and the goal for most Data Science WorkFlows.\n",
    "\n",
    "Apache Spark created a library called MLlib where they coded great algorithms for Machine Learning. Now with the ML library we can take advantage of the Dataframe API and its optimization to create easily Machine Learning Pipelines.\n",
    "\n",
    "Even though this task is not extremely hard, is not easy. The way most Machine Learning models work on Spark are not straightforward, and they need lots feature engineering to work. That’s why we created the feature engineering section inside the Transformer.\n",
    "\n",
    "To import the Machine Learning Library you just need to import Optimus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing Optimus\n",
    "import optimus as op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with Optimus you can use this really easy feature engineering with our Machine Learning Library.\n",
    "\n",
    "Let’s take a look of what Optimus can do for you:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ml.logistic_regression_text(df, input_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method runs a logistic regression for input (text) DataFrame.\n",
    "\n",
    "Let’s create a sample dataframe to see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Row from pyspark\n",
    "from pyspark.sql import Row\n",
    "# Importing Optimus\n",
    "import optimus as op\n",
    "\n",
    "df = op.sc. \\\n",
    "    parallelize([Row(sentence='this is a test', label=0.),\n",
    "                 Row(sentence='this is another test', label=1.)]). \\\n",
    "    toDF()\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_predict, ml_model = op.ml.logistic_regression_text(df, \"sentence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This instruction will return two things, first the DataFrame with predictions and steps to build it with a pipeline and a Spark machine learning model where the third step will be the logistic regression.\n",
    "\n",
    "The columns of df_predict are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_predict.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The names are long because those are the uid for each step in the pipeline. So lets see the prediction compared with the actual labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformer = op.DataFrameTransformer(df_predict)\n",
    "transformer.select_idx([0,6]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we just did ML with a single line in Optimus. The model is also exposed in the ml_model variable so you can save it and evaluate it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ml.n_gram(df, input_col, n=2)\n",
    "\n",
    "\n",
    "This method converts the input array of strings inside of a Spark DF into an array of n-grams. The default n is 2 so\n",
    "it will produce bi-grams.\n",
    "\n",
    "Let's create a sample dataframe to see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Row from pyspark\n",
    "from pyspark.sql import Row,types\n",
    "# Importing Optimus\n",
    "import optimus as op\n",
    "\n",
    "df = op.sc. \\\n",
    "parallelize([['this is the best sentence ever'],\n",
    "             ['this is however the worst sentence available']]). \\\n",
    "toDF(schema=types.StructType().add('sentence', types.StringType()))\n",
    "\n",
    "df_predict, model = op.ml.n_gram(df, input_col=\"sentence\", n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns of df_predict are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_predict.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So lets see the bi-grams (we can change n as we want) for the sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformer = op.DataframeTransformer(df_predict)\n",
    "transformer.select_idx([0,4]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it. N-grams with only one line of code.\n",
    "\n",
    "Above we've been using the Pyspark Pipes definitions of Daniel Acuña, that he merged with Optimus, and because\n",
    "we use multiple pipelines we need those big names for the resulting columns, so we can know which uid correspond\n",
    "to each step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree models with Optimus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can build Decision Trees, Random Forest models and also Gradient Boosted Trees with just one line of code in Optimus. Let’s download some sample data for analysis.\n",
    "\n",
    "We got this dataset from Kaggle. The features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. n the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: “Robust Linear Programming Discrimination of Two Linearly Inseparable Sets”, Optimization Methods and Software 1, 1992, 23-34].\n",
    "\n",
    "Let’s download it with Optimus and save it into a DF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing Optimus utils\n",
    "tools = op.Utilities()\n",
    "\n",
    "# Downloading and creating Spark DF\n",
    "df = tools.read_url(\"https://raw.githubusercontent.com/ironmussa/Optimus/master/tests/data_cancer.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll choose some columns to run the Machine Learning models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ['diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean',\n",
    "           'compactness_mean', 'concavity_mean', 'concave points_mean', 'symmetry_mean','fractal_dimension_mean']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ml.decision_tree(df, columns, input_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_predict, dt_model = op.ml.decision_tree(df, columns, \"diagnosis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_predict.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol='label')\n",
    "print(evaluator.evaluate(df_predict, \n",
    "     {evaluator.metricName: \"areaUnderROC\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ml.random_forest(df, columns, input_col)\n",
    "\n",
    "One of the best tree models for machine learning is Random Forest. What about creating a RF model with just\n",
    "one line? With Optimus is really easy.\n",
    "\n",
    "Let's download some sample data for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Downloading and creating Spark DF\n",
    "df = tools.read_url(\"https://raw.githubusercontent.com/ironmussa/Optimus/master/tests/data_cancer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_predict, rf_model = op.ml.random_forest(df_cancer, columns, \"diagnosis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will create a DataFrame with the predictions of the Random Forest model.\n",
    "\n",
    "Let's see df_predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So lets see the prediction compared with the actual label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformer = op.DataframeTransformer(df_predict)\n",
    "transformer.select_idx([0,15]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol='label')\n",
    "print(evaluator.evaluate(df_predict, \n",
    "     {evaluator.metricName: \"areaUnderROC\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ml.gbt(df, columns, input_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Downloading and creating Spark DF\n",
    "df = tools.read_url(\"https://raw.githubusercontent.com/ironmussa/Optimus/master/tests/data_cancer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_predict, gbt_model = op.ml.gbt(df_cancer, columns, \"diagnosis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will create a DataFrame with the predictions of the Gradient Boosted Trees model.\n",
    "\n",
    "Let's see df_predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_predict.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformer = op.DataframeTransformer(df_predict)\n",
    "transformer.select_idx([0,15]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol='label')\n",
    "print(evaluator.evaluate(df_predict, \n",
    "     {evaluator.metricName: \"areaUnderROC\"}))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
