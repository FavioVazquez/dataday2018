{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimus Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook is a simple tutorial about DataFrameTransformer, DataFrameAnalyzer and Utilities modules.\n",
    "\n",
    "- DataFrameTransformer is a dedicated module to easily make dataframe transformations. \n",
    "\n",
    "- DataFrameProfiler is a dedicated module to run a basic profile of the dataframe.\n",
    "\n",
    "- DataFrameAnalyzer is a dedicated module to plot and see important features of a spark\n",
    " Dataframe.\n",
    "\n",
    "- Utilities module contains tool classes that support use of DataFrameTransformer and DataFrameAnalyzer modules. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import optimus\n",
    "import optimus as op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiation of Utility class\n",
    "The utility class is a tool class that includes functions to read csv files, setting checkpoint issues (to save or temporally save dataFrames)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instance of Utilities class\n",
    "tools = op.Utilities()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reading dataframe in this case, local file \n",
    "#Â system (hard drive of the pc) is used.\n",
    "\n",
    "df = tools.read_csv(path=\"foo.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General view of DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially it is a good idea to see a general view of the DataFrame to be analyzed. \n",
    "\n",
    "In the following cell, a basic profile of the DataFrame is shown. This overview presents basic information about the DataFrame, like number of variable it has, how many are missing values and in which column, the types of each varaible, also some statistical information that describes the variable plus a frecuency plot. table that specifies the existing datatypes in each column dataFrame and other features. Also, for this particular case, the table of dataType is shown in order to visualize a sample of column content. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Instance of profiler class\n",
    "profiler = op.DataFrameProfiler(df)\n",
    "profiler.profiler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiation of analyzer class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if you want more information for data exploration, Optimus has the DataFrameAnalizer which has several functions for analyzing your dataset. It presents a table that specifies the existing datatypes in each column dataFrame and other features. Also, for this particular case, the table of dataType is shown in order to visualize a sample of column content. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instance of analyzer class\n",
    "analyzer = op.DataFrameAnalyzer(df=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrameAnalizer has a method called columnAnalize. This method can check all rows of\n",
    "dataFrame and tries to parse each element of each row to determine if the corresponding \n",
    "element is a string or a number. Besides, it can show 20 distinct values of each column\n",
    "classified according the possible datatype value, i.e: a number can be a string, so this \n",
    "function can recognize a number in a column of string dataType by trying to parse the string. \n",
    "\n",
    "Also the function can plot numerical or categorical histograms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General view of DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially it is a good idea to see a general view of the DataFrame to be analyzed. \n",
    "\n",
    "In the following cell, the basic results of analyzing the DataFrame are made are shown. Basic results include a table that specifies the existing datatypes in each column dataFrame and other features. Also, for this particular case, the table of dataType is shown in order to visualize a sample of column content. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "analyzer_tables = analyzer.column_analyze(column_list=\"*\", print_type=True, plots=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results obtained by running the analyzer class, details the presence of special chars, \n",
    "string columns with possible numbers on them and None and empty string values in columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also plot histograms for individual columns using the `plot_hist` function. This is an interesting feature because you are plotting from a Spark Dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.plot_hist(\"price\",\"numerical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiation of DataFrameTransformer\n",
    "DataFrameTransformer is a specialized class to make dataFrame transformations. Transformations are optimized as much as possible to internally used native spark \n",
    "transformation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instance of transformer class \n",
    "transformer = op.DataFrameTransformer(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trimming blanck spaces at beginning and endings of cells dataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing of original dataFrame:\n",
    "print('Original dataFrame:')\n",
    "transformer.show(5)\n",
    "\n",
    "# Triming string blank spaces:\n",
    "transformer.trim_col(\"*\")\n",
    "\n",
    "# Printing trimmed dataFrame:\n",
    "print('Trimmed dataFrame:')\n",
    "transformer.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing especial chars and accents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing of original dataFrame:\n",
    "print('Original dataFrame:')\n",
    "transformer.show(5)\n",
    "\n",
    "# Remove special chars:\n",
    "transformer.remove_special_chars(\"*\").clear_accents(\"*\")\n",
    "\n",
    "# This can also be done by passing a Regex if you want something more personalized\n",
    "\n",
    "#####################################################################\n",
    "\n",
    "#transformer.remove_special_chars_regex(\"*\",'[^\\w\\s]').clear_accents(\"*\")\n",
    "\n",
    "#####################################################################\n",
    "\n",
    "# Printing trimmed dataFrame:\n",
    "print('Removing special chars and accents dataFrame:')\n",
    "transformer.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop dummy column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing of original dataFrame:\n",
    "print('Original dataFrame:')\n",
    "transformer.show(5)\n",
    "\n",
    "# Droping a column:\n",
    "transformer.drop_col(\"dummyCol\")\n",
    "\n",
    "# Printing trimmed dataFrame:\n",
    "print('Dataframe without dummy column:')\n",
    "transformer.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting all letters to lowerCase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing of original dataFrame:\n",
    "print('Original dataFrame:')\n",
    "transformer.show(5)\n",
    "\n",
    "print('Setting all letters to lowerCase:')\n",
    "transformer.lower_case(\"*\")\n",
    "transformer.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date Transformation (Format of date is changed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing of original dataFrame:\n",
    "print('Original dataFrame:')\n",
    "transformer.show(5)\n",
    "\n",
    "# Priting the new date format:\n",
    "print('Dataframe without dummy column:')\n",
    "transformer.date_transform(\"birth\", \"yyyyMMdd\", \"dd-MM-YYYY\") \\\n",
    "           .show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age calculation from birth date client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing of original dataFrame:\n",
    "print('Original dataFrame:')\n",
    "transformer.show(5)\n",
    "\n",
    "print(\"Printing calculation of age born date client\")\n",
    "transformer.age_calculate(\"birth\", \"dd-MM-YYYY\", \"clientAge\") \\\n",
    "           .show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing original dataframe:\n",
    "print (\"Original dataframe\")\n",
    "transformer.show(5)\n",
    "print (\"Renaming some columns of dataFrame\")\n",
    "transformer.rename_col(columns=[(\"clientAge\", \"age\")])\n",
    "transformer.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing positions of columns dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing original dataframe:\n",
    "print (\"Original dataframe\")\n",
    "transformer.show(5)\n",
    "\n",
    "# This action is to move column age, just after the lastName column\n",
    "print (\"age column moved\")\n",
    "transformer.move_col(\"age\", \"lastName\", \"after\")\n",
    "transformer.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting a custom transformation\n",
    "The core of this function is base on the user define function provide from the lambda function provided in the 'func' argument. \n",
    "\n",
    "In this example, cells that are not greater than 20, are multiplied by 20, the rest of them stay intact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing original dataframe:\n",
    "print (\"Original dataframe\")\n",
    "transformer.show(5)\n",
    "\n",
    "print (' Multiplying by 20 a number if value in cell is greater than 20:')\n",
    "# Replacing a number:   \n",
    "func = lambda cell: (cell * 20) if ((cell != None) and (cell < 20)) else cell\n",
    "transformer.set_col(['price'], func, 'integer')\n",
    "transformer.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the transformation process detailed in the previous cells. It is a good idea to\n",
    "analyze to see if the transformations have solved issued related with special characters, \n",
    "presence of number in column where is to supposed only letters, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing columns after transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Setting the new dataFrame transformed into the analyzer class\n",
    "analyzer.set_data_frame(transformer.df)\n",
    "analyzer_table = analyzer.column_analyze(\"*\", print_type=True, plots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen from output of the analyzer object, that there are columns with numbers\n",
    "even when ceratin column (for example) is supposed to be only of words or letters. \n",
    "\n",
    "In order to solve this problem, operationInType function of DataFrameTransformer class \n",
    "can be used. \n",
    "\n",
    "operationInType function is useful to make operations in a certain element of one dataType. In this particular example, it can be seen in the last output cell (specifically in 'product' column' that are values that don't fit the rest of the data, the aren't strings but they are numbers or empty strings. operationInType can take care about them and clean the column dataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following example, operationInType of function of DataFrameTransformer class is run in order to converts all posible \n",
    "parsables strings to integer into a null or none value. Notice how the 110790 value in product\n",
    "column have been changed, but the rest of the column has remained intact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making transformation in the inferred dataType elements of a certains columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function makes changes or transformation in the column specified only in the cells\n",
    "# that are recognized as the dataType specified. \n",
    "transformer.operation_in_type([('product', 'integer', None)]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes there a some values that are different but actually are the same. In the product\n",
    "column for example, there are the following values: 'taaaccoo', 'piza'. It \n",
    "can be inferred that the correct value is taco and piza and not the rest of them. This problem can\n",
    "be solved with the lookup function of the DataFrameTransformer class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing multiple string values to a single string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.lookup('product', str_to_replace='taco', list_str=['taaaccoo']) \n",
    "transformer.lookup('product', str_to_replace='pizza', list_str=['piza', 'pizzza']) \n",
    "transformer.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be notice above, string specified in the list argument 'list_str' have been\n",
    "replaced to 'str_to_replace' value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chaining and lazy evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The past transformations were done step by step, but this can be achieved by chaining\n",
    "all operations into one line of code, like the cell below. This way is much more efficient and scalable because it uses all optimization issues from the lazy evaluation approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the transformation set before can be done into a single line of code thanks to the \n",
    "chaining feature of the DataFrameTransformer class. This option is a optimal way to \n",
    "make different transformations, because it uses as much as possible all advantages of\n",
    "the lazy evaluation approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciate DataFrameTransfomer\n",
    "transformer = op.DataFrameTransformer(df)\n",
    "# Get original dataFrame to show it.\n",
    "transformer.show(20)\n",
    "\n",
    "# Chaining function transformations\n",
    "transformer.trim_col(\"*\") \\\n",
    "           .remove_special_chars(\"*\") \\\n",
    "           .clear_accents(\"*\") \\\n",
    "           .lower_case(\"*\") \\\n",
    "           .drop_col(\"dummyCol\") \\\n",
    "           .date_transform(\"birth\", \"yyyyMMdd\", \"dd-MM-YYYY\") \\\n",
    "           .age_calculate(\"birth\", \"dd-MM-YYYY\", \"clientAge\") \\\n",
    "           .operation_in_type([('product', 'integer', None)]) \\\n",
    "           .lookup('product', str_to_replace='taco', list_str=['taaaccoo']) \\\n",
    "           .lookup('product', str_to_replace='pizza', list_str=['piza', 'pizzza'])  \\\n",
    "        \n",
    "        \n",
    "transformer.show(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
